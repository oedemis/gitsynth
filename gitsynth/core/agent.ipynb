{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langgraph ollama unidiff langchain-ollama langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from typing import Annotated, Sequence, List, Optional, Literal, Any, Dict\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "import os\n",
    "from unidiff import PatchSet, PatchedFile\n",
    "from io import StringIO\n",
    "import json\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "from rich.syntax import Syntax\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod  # Neuer Import\n",
    "from pathlib import Path\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GitFileChange(BaseModel):\n",
    "    \"\"\"Detailed analysis of a single file change\"\"\"\n",
    "    path: str\n",
    "    change_type: Literal[\"NEW\", \"DELETED\", \"RENAMED\", \"MODE_CHANGED\", \"MODIFIED\", \"BINARY\", \"SUBMODULE\", \"CONFLICT\"]\n",
    "    old_path: Optional[str] = None\n",
    "    added_lines: int = 0\n",
    "    removed_lines: int = 0\n",
    "    hunks: List[dict] = Field(default_factory=list)\n",
    "    purpose: str = Field(description=\"Description of what changed and why\")\n",
    "\n",
    "class GitDiffAnalysis(BaseModel):\n",
    "    \"\"\"Structured Analysis of Git Changes\"\"\"\n",
    "    summary: str = Field(description=\"Brief technical summary of all changes\")\n",
    "    change_type: Literal[\"feat\", \"fix\", \"docs\", \"refactor\", \"test\", \"chore\", \"style\", \"perf\"]\n",
    "    files: List[GitFileChange]\n",
    "    breaking_change: bool = Field(default=False)\n",
    "\n",
    "class ConventionalCommit(BaseModel):\n",
    "    \"\"\"Structured Conventional Commit Message\"\"\"\n",
    "    type: Literal[\"feat\", \"fix\", \"docs\", \"refactor\", \"test\", \"chore\", \"style\", \"perf\"]\n",
    "    scope: Optional[str] = None\n",
    "    description: str = Field(description=\"Imperative description of the change\")\n",
    "    breaking: bool = False\n",
    "    body: Optional[str] = None\n",
    "    footer: Optional[str] = None\n",
    "\n",
    "class CommitQuality(BaseModel):\n",
    "    \"\"\"Binary Quality Check Result\"\"\"\n",
    "    is_valid: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import (\n",
    "    Annotated,\n",
    "    Sequence,\n",
    "    TypedDict,\n",
    ")\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "\n",
    "## Agent State      \n",
    "class AgentState(TypedDict):\n",
    "#class AgentState(MessagesState):\n",
    "    \"\"\"Speichert den aktuellen Zustand des Agenten\"\"\"\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    #messages: Annotated[list, add_messages]\n",
    "    #final_response: GitFileChange\n",
    "\n",
    "    \n",
    "graph_builder = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "agent_llm = ChatOllama(\n",
    "    model=\"granite3-dense:8b\",\n",
    "    temperature=0,\n",
    "    # other params...\n",
    ")\n",
    "#.bind_tools([parse_git_diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "#@tool\n",
    "def parse_git_diff(diff_text: str) -> List[GitFileChange]:\n",
    "    \"\"\"\n",
    "    Parses Git-Diffs into a List of GitFileChange structure\n",
    "    \"\"\"\n",
    "    patch_set = PatchSet(StringIO(diff_text))\n",
    "    changes: List[GitFileChange] = []\n",
    "    \n",
    "    print(f\"Found {len(patch_set)} files in diff\")\n",
    "    \n",
    "    for patched_file in patch_set:\n",
    "        # Basis-Informationen\n",
    "        path = patched_file.path.lstrip('b/')  # Entferne 'b/' Prefix\n",
    "        \n",
    "        # Change Type Detection\n",
    "        if patched_file.is_added_file:  # Neue Datei\n",
    "            change_type = \"NEW\"\n",
    "            old_path = None\n",
    "            print(f\"NEW file: {path}\")\n",
    "        elif patched_file.is_removed_file:  # Gelöschte Datei\n",
    "            change_type = \"DELETED\"\n",
    "            old_path = patched_file.source_file.lstrip('a/')\n",
    "            print(f\"DELETED file: {path}\")\n",
    "        elif patched_file.is_rename:  # Umbenannte Datei\n",
    "            change_type = \"RENAMED\"\n",
    "            old_path = patched_file.source_file.lstrip('a/')\n",
    "            print(f\"RENAMED file from {old_path} to {path}\")\n",
    "        elif patched_file.is_binary_file:  # Binärdatei\n",
    "            change_type = \"BINARY\"\n",
    "            old_path = None\n",
    "            print(f\"BINARY file: {path}\")\n",
    "        else:  # Normale Änderung\n",
    "            change_type = \"MODIFIED\"\n",
    "            old_path = None\n",
    "            print(f\"MODIFIED file: {path}\")\n",
    "            \n",
    "        # Hunk Analysis\n",
    "        hunks = []\n",
    "        total_added = 0\n",
    "        total_removed = 0\n",
    "        \n",
    "        for hunk in patched_file:\n",
    "            added = len([l for l in hunk if l.is_added])\n",
    "            removed = len([l for l in hunk if l.is_removed])\n",
    "            total_added += added\n",
    "            total_removed += removed\n",
    "            \n",
    "            hunk_info = {\n",
    "                \"old_start\": hunk.source_start,\n",
    "                \"old_length\": hunk.source_length,\n",
    "                \"new_start\": hunk.target_start,\n",
    "                \"new_length\": hunk.target_length,\n",
    "                \"added_lines\": added,\n",
    "                \"removed_lines\": removed,\n",
    "                \"modified_lines\": len(hunk)\n",
    "            }\n",
    "            hunks.append(hunk_info)\n",
    "            \n",
    "        print(f\"  Lines: +{total_added} -{total_removed}\")\n",
    "            \n",
    "        # Erstelle direkt ein GitFileChange-Objekt\n",
    "        change = GitFileChange(\n",
    "            path=path,\n",
    "            change_type=change_type,\n",
    "            old_path=old_path,\n",
    "            added_lines=total_added,\n",
    "            removed_lines=total_removed,\n",
    "            hunks=hunks,\n",
    "            purpose=\"\"  # Soll von LLM gefüllt werden\n",
    "        )\n",
    "        changes.append(change)  # Füge das Objekt direkt hinzu\n",
    "    \n",
    "    return changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second node with ollama python\n",
    "# Node: retrieve_parsed_diff where everything is started\n",
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "# @tool\n",
    "def retrieve_parsed_diff(state: AgentState):\n",
    "    messages = state[\"messages\"]\n",
    "    diff_text = messages[0].content\n",
    "\n",
    "    response = chat(\n",
    "        model=\"llama3.2\",\n",
    "        messages=[{\"role\": \"user\", \"content\": diff_text}],\n",
    "        # format_schema=GitFileChange.model_json_schema(),\n",
    "        options={\"temperature\": 0},\n",
    "        tools=[parse_git_diff],\n",
    "    )\n",
    "\n",
    "    # response_typed = GitDiffAnalysis.model_validate_json(response.message.content)\n",
    "    available_functions = {\n",
    "        \"parse_git_diff\": parse_git_diff\n",
    "    }\n",
    "    for tool in response.message.tool_calls or []:\n",
    "      function_to_call = available_functions.get(tool.function.name)\n",
    "      print(\"function_to_call\", function_to_call)\n",
    "      if function_to_call:\n",
    "        final_response = function_to_call(**tool.function.arguments)\n",
    "        print(\"final_response\", final_response)\n",
    "      else:\n",
    "        print('Function not found:', tool.function.name)\n",
    "\n",
    "    return {\"messages\": [final_response]}\n",
    "    # return {\"messages\": [agent_llm.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11dd59f90>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_node(\"get_diff\", retrieve_parsed_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [parse_git_diff, GitFileChange, GitDiffAnalysis]\n",
    "agent_llm = agent_llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Node `get_diff` already present.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[131], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [response]}\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m#return {\"messages\": [agent_llm.invoke(state[\"messages\"])]}\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m \u001b[43mgraph_builder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_node\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget_diff\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretrieve_parsed_diff\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/withray/lib/python3.11/site-packages/langgraph/graph/state.py:352\u001b[0m, in \u001b[0;36mStateGraph.add_node\u001b[0;34m(self, node, action, metadata, input, retry)\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes:\n\u001b[0;32m--> 352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNode `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` already present.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;241m==\u001b[39m END \u001b[38;5;129;01mor\u001b[39;00m node \u001b[38;5;241m==\u001b[39m START:\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNode `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` is reserved.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Node `get_diff` already present."
     ]
    }
   ],
   "source": [
    "# Node: retrieve_parsed_diff where everything is started\n",
    "def retrieve_parsed_diff(state: AgentState):\n",
    "    messages = state[\"messages\"]\n",
    "    diff_text = messages[0].content\n",
    "        \n",
    "    #llm_with_tool = agent_llm.with_structured_output(GitDiffAnalysis)\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "        You are a git diff parser. You are given a git diff and you need to provide a detailed JSON output with detailes included.\\n\\n\n",
    "        Here is the git diff: {diff_text}\\n\\n\n",
    "        \n",
    "        I want a very detailed analysis with:\n",
    "        1. Technical Analysis\n",
    "        - Number and types of files changed\n",
    "        - Lines added/removed per file\n",
    "        - Location of changes in the codebase\n",
    "        - Pattern of modifications (hunks distribution) \\n\\n\n",
    "\n",
    "        2. Change Classification\n",
    "        - Determine the primary change type (feat/fix/docs/etc.)\n",
    "        - Identify if changes are breaking or non-breaking\n",
    "        - Assess the scope of the changes \\n\\n\n",
    "\n",
    "        3. Purpose Assessment\n",
    "        For each modified file:\n",
    "        - Technical purpose of the changes\n",
    "        - Impact on the codebase\n",
    "        - Relationship to other changed files\n",
    "        - Context within the broader system\\n\\n\n",
    "\n",
    "        4. Summary\n",
    "        - Brief technical overview\n",
    "        - Key impacts and implications\n",
    "        - Related components affected\\n\\n\n",
    "\n",
    "        \n",
    "        Please provide a structured analysis based on the Git diff data as JSON.\n",
    "        Please use available tools to get the information you need.\n",
    "        \n",
    "        \"\"\",\n",
    "        input_variables=[\"diff_text\"]\n",
    "    )\n",
    "    chain = prompt | agent_llm\n",
    "    \n",
    "    response = chain.invoke({\"diff_text\": diff_text})\n",
    "    return {\"messages\": [response]}\n",
    "    #return {\"messages\": [agent_llm.invoke(state[\"messages\"])]}\n",
    "    \n",
    "graph_builder.add_node(\"get_diff\", retrieve_parsed_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11dd59f90>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(START, \"get_diff\")\n",
    "graph_builder.add_edge(\"get_diff\", END)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      " Following git-diff, make a structured analysis of the changes: \n",
      "\n",
      "    diff --git a/old-name.ts b/new-name.ts\n",
      "    similarity index 100%\n",
      "    rename from old-name.ts\n",
      "    rename to new-name.ts\n",
      "\n",
      "function_to_call <function parse_git_diff at 0x11d779e40>\n",
      "Found 1 files in diff\n",
      "RENAMED file from old-name.ts to new-name.ts\n",
      "  Lines: +0 -0\n",
      "final_response [GitFileChange(path='new-name.ts', change_type='RENAMED', old_path='old-name.ts', added_lines=0, removed_lines=0, hunks=[], purpose='')]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Unsupported message type: <class 'list'>\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/MESSAGE_COERCION_FAILURE ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[135], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#diff = query\u001b[39;00m\n\u001b[1;32m     14\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, diff)]}\n\u001b[0;32m---> 15\u001b[0m \u001b[43mprint_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[135], line 3\u001b[0m, in \u001b[0;36mprint_stream\u001b[0;34m(stream)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_stream\u001b[39m(stream):\n\u001b[0;32m----> 3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/withray/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1655\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1649\u001b[0m     get_waiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m   1650\u001b[0m \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1651\u001b[0m \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1653\u001b[0m \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[0;32m-> 1655\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_channels\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   1657\u001b[0m         loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   1658\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1661\u001b[0m     ):\n\u001b[1;32m   1662\u001b[0m         \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   1663\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m output()\n",
      "File \u001b[0;32m~/anaconda3/envs/withray/lib/python3.11/site-packages/langgraph/pregel/loop.py:386\u001b[0m, in \u001b[0;36mPregelLoop.tick\u001b[0;34m(self, input_keys)\u001b[0m\n\u001b[1;32m    376\u001b[0m     print_step_writes(\n\u001b[1;32m    377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep,\n\u001b[1;32m    378\u001b[0m         writes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    383\u001b[0m         ),\n\u001b[1;32m    384\u001b[0m     )\n\u001b[1;32m    385\u001b[0m \u001b[38;5;66;03m# all tasks have finished\u001b[39;00m\n\u001b[0;32m--> 386\u001b[0m mv_writes \u001b[38;5;241m=\u001b[39m \u001b[43mapply_writes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpointer_get_next_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;66;03m# apply writes to managed values\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, values \u001b[38;5;129;01min\u001b[39;00m mv_writes\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/anaconda3/envs/withray/lib/python3.11/site-packages/langgraph/pregel/algo.py:293\u001b[0m, in \u001b[0;36mapply_writes\u001b[0;34m(checkpoint, channels, tasks, get_next_version)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chan, vals \u001b[38;5;129;01min\u001b[39;00m pending_writes_by_channel\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chan \u001b[38;5;129;01min\u001b[39;00m channels:\n\u001b[0;32m--> 293\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mchannels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchan\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m get_next_version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    294\u001b[0m             checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m][chan] \u001b[38;5;241m=\u001b[39m get_next_version(\n\u001b[1;32m    295\u001b[0m                 max_version,\n\u001b[1;32m    296\u001b[0m                 channels[chan],\n\u001b[1;32m    297\u001b[0m             )\n\u001b[1;32m    298\u001b[0m         updated_channels\u001b[38;5;241m.\u001b[39madd(chan)\n",
      "File \u001b[0;32m~/anaconda3/envs/withray/lib/python3.11/site-packages/langgraph/channels/binop.py:88\u001b[0m, in \u001b[0;36mBinaryOperatorAggregate.update\u001b[0;34m(self, values)\u001b[0m\n\u001b[1;32m     86\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m values:\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/withray/lib/python3.11/site-packages/langgraph/graph/message.py:76\u001b[0m, in \u001b[0;36madd_messages\u001b[0;34m(left, right)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# coerce to message\u001b[39;00m\n\u001b[1;32m     70\u001b[0m left \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     71\u001b[0m     message_chunk_to_message(cast(BaseMessageChunk, m))\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m convert_to_messages(left)\n\u001b[1;32m     73\u001b[0m ]\n\u001b[1;32m     74\u001b[0m right \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     75\u001b[0m     message_chunk_to_message(cast(BaseMessageChunk, m))\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mconvert_to_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m ]\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# assign missing ids\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m left:\n",
      "File \u001b[0;32m~/anaconda3/envs/withray/lib/python3.11/site-packages/langchain_core/messages/utils.py:357\u001b[0m, in \u001b[0;36mconvert_to_messages\u001b[0;34m(messages)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(messages, PromptValue):\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m messages\u001b[38;5;241m.\u001b[39mto_messages()\n\u001b[0;32m--> 357\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43m_convert_to_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/withray/lib/python3.11/site-packages/langchain_core/messages/utils.py:357\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(messages, PromptValue):\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m messages\u001b[38;5;241m.\u001b[39mto_messages()\n\u001b[0;32m--> 357\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43m_convert_to_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages]\n",
      "File \u001b[0;32m~/anaconda3/envs/withray/lib/python3.11/site-packages/langchain_core/messages/utils.py:336\u001b[0m, in \u001b[0;36m_convert_to_message\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m    334\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported message type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(message)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    335\u001b[0m     msg \u001b[38;5;241m=\u001b[39m create_message(message\u001b[38;5;241m=\u001b[39mmsg, error_code\u001b[38;5;241m=\u001b[39mErrorCode\u001b[38;5;241m.\u001b[39mMESSAGE_COERCION_FAILURE)\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _message\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Unsupported message type: <class 'list'>\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/MESSAGE_COERCION_FAILURE "
     ]
    }
   ],
   "source": [
    "# Helper function for formatting the stream nicely\n",
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        message.pretty_print()\n",
    "\n",
    "diff = \"\"\" Following git-diff, make a structured analysis of the changes: \\n\n",
    "    diff --git a/old-name.ts b/new-name.ts\n",
    "    similarity index 100%\n",
    "    rename from old-name.ts\n",
    "    rename to new-name.ts\n",
    "\"\"\"\n",
    "#diff = query\n",
    "inputs = {\"messages\": [(\"user\", diff)]}\n",
    "print_stream(graph.stream(inputs, stream_mode=\"values\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReACT Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from typing import Sequence, Annotated, Optional\n",
    "\n",
    "# 1. Zustandsklasse\n",
    "class AgentState(MessagesState):\n",
    "    \"\"\"Speichert den aktuellen Zustand des Agenten\"\"\"\n",
    "    final_response: Optional[GitFileChange] = None\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "\n",
    "# 2. Model und Tools Setup\n",
    "tools = [parse_git_diff]\n",
    "model_with_tools = agent_llm.bind_tools(tools)\n",
    "model_with_structured_output = agent_llm.with_structured_output(GitFileChange)\n",
    "\n",
    "# 3. Nodes\n",
    "def call_model(state: AgentState):\n",
    "    \"\"\"Ruft das Modell auf\"\"\"\n",
    "    response = model_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def respond(state: AgentState):\n",
    "    \"\"\"Erstellt strukturierte Antwort\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Finde das Tool-Ergebnis\n",
    "    tool_result = None\n",
    "    for msg in reversed(messages):\n",
    "        if hasattr(msg, 'content') and isinstance(msg.content, str):\n",
    "            tool_result = msg.content\n",
    "            break\n",
    "    \n",
    "    if not tool_result:\n",
    "        raise ValueError(\"Kein Tool-Ergebnis gefunden\")\n",
    "        \n",
    "    response = model_with_structured_output.invoke([\n",
    "        HumanMessage(content=f\"\"\"Analyze this git diff and create a GitFileChange:\n",
    "        - Determine the file path\n",
    "        - Identify the change type (NEW/MODIFIED/etc.)\n",
    "        - Count added and removed lines\n",
    "        - Describe the purpose of the change\n",
    "\n",
    "        Git diff:\n",
    "        {tool_result}\n",
    "        \"\"\")\n",
    "    ])\n",
    "    return {\"final_response\": response}\n",
    "\n",
    "# 4. Graph Setup\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", ToolNode(tools))\n",
    "workflow.add_node(\"respond\", respond)\n",
    "\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# 5. Routing\n",
    "def should_continue(state: AgentState):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if not last_message.tool_calls:\n",
    "        return \"respond\"\n",
    "    return \"continue\"\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"tools\",\n",
    "        \"respond\": \"respond\",\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "workflow.add_edge(\"respond\", END)\n",
    "\n",
    "# Graph kompilieren\n",
    "graph = workflow.compile()\n",
    "\n",
    "# 6. Helper für die Ausgabe\n",
    "def print_file_change(change: GitFileChange):\n",
    "    \"\"\"Zeigt die GitFileChange-Informationen an\"\"\"\n",
    "    print(\"\\n=== Git File Change ===\")\n",
    "    print(f\"Datei: {change.path}\")\n",
    "    print(f\"Änderungstyp: {change.change_type}\")\n",
    "    if change.old_path:\n",
    "        print(f\"Alter Pfad: {change.old_path}\")\n",
    "    print(f\"Zeilen: +{change.added_lines} -{change.removed_lines}\")\n",
    "    print(f\"Zweck: {change.purpose}\")\n",
    "    if change.hunks:\n",
    "        print(f\"Anzahl Hunks: {len(change.hunks)}\")\n",
    "\n",
    "# 7. Verwendung\n",
    "def analyze_git_change(diff_content: str):\n",
    "    \"\"\"Analysiert eine einzelne Dateiänderung\"\"\"\n",
    "    inputs = {\n",
    "        \"messages\": [HumanMessage(content=diff_content)]\n",
    "    }\n",
    "    \n",
    "    for output in graph.stream(inputs, stream_mode=\"values\"):\n",
    "        if \"final_response\" in output and output[\"final_response\"]:\n",
    "            print_file_change(output[\"final_response\"])\n",
    "        elif \"messages\" in output:\n",
    "            for msg in output[\"messages\"]:\n",
    "                if hasattr(msg, \"content\"):\n",
    "                    print(f\"\\n{msg.type}: {msg.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "human: \n",
      "    diff --git a/script.sh b/script.sh\n",
      "    index 1234567..89abcde 100644\n",
      "    --- a/script.sh\n",
      "    +++ b/script.sh\n",
      "    @@ -1,3 +1,7 @@\n",
      "    +fi\n",
      "    +\n",
      "    +# Check if there are any staged changes\n",
      "    +diff=$(git diff --cached | cat)\n",
      "    +if [ -z \"$diff\" ]; then\n",
      "    +  echo \"No staged changes to commit.\"\n",
      "    +  exit 1\n",
      "    \n",
      "\n",
      "human: \n",
      "    diff --git a/script.sh b/script.sh\n",
      "    index 1234567..89abcde 100644\n",
      "    --- a/script.sh\n",
      "    +++ b/script.sh\n",
      "    @@ -1,3 +1,7 @@\n",
      "    +fi\n",
      "    +\n",
      "    +# Check if there are any staged changes\n",
      "    +diff=$(git diff --cached | cat)\n",
      "    +if [ -z \"$diff\" ]; then\n",
      "    +  echo \"No staged changes to commit.\"\n",
      "    +  exit 1\n",
      "    \n",
      "\n",
      "ai: Based on the provided Git diff, here's a breakdown of the changes:\n",
      "\n",
      "1. Two new lines have been added at the beginning of the script. These lines are `fi` and a comment `# Check if there are any staged changes`.\n",
      "2. A new block of code has been added after the existing code. This block checks if there are any staged changes using the `git diff --cached` command. If there are no staged changes, it prints \"No staged changes to commit.\" and exits with a status code of 1.\n",
      "\n",
      "Here's the parsed GitFileChange structure:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"type\": \"add\",\n",
      "  \"path\": \"script.sh\",\n",
      "  \"content\": [\n",
      "    {\n",
      "      \"start_line\": 1,\n",
      "      \"end_line\": 1,\n",
      "      \"new_content\": \"fi\"\n",
      "    },\n",
      "    {\n",
      "      \"start_line\": 2,\n",
      "      \"end_line\": 2,\n",
      "      \"new_content\": \"# Check if there are any staged changes\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "human: \n",
      "    diff --git a/script.sh b/script.sh\n",
      "    index 1234567..89abcde 100644\n",
      "    --- a/script.sh\n",
      "    +++ b/script.sh\n",
      "    @@ -1,3 +1,7 @@\n",
      "    +fi\n",
      "    +\n",
      "    +# Check if there are any staged changes\n",
      "    +diff=$(git diff --cached | cat)\n",
      "    +if [ -z \"$diff\" ]; then\n",
      "    +  echo \"No staged changes to commit.\"\n",
      "    +  exit 1\n",
      "    \n",
      "\n",
      "ai: Based on the provided Git diff, here's a breakdown of the changes:\n",
      "\n",
      "1. Two new lines have been added at the beginning of the script. These lines are `fi` and a comment `# Check if there are any staged changes`.\n",
      "2. A new block of code has been added after the existing code. This block checks if there are any staged changes using the `git diff --cached` command. If there are no staged changes, it prints \"No staged changes to commit.\" and exits with a status code of 1.\n",
      "\n",
      "Here's the parsed GitFileChange structure:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"type\": \"add\",\n",
      "  \"path\": \"script.sh\",\n",
      "  \"content\": [\n",
      "    {\n",
      "      \"start_line\": 1,\n",
      "      \"end_line\": 1,\n",
      "      \"new_content\": \"fi\"\n",
      "    },\n",
      "    {\n",
      "      \"start_line\": 2,\n",
      "      \"end_line\": 2,\n",
      "      \"new_content\": \"# Check if there are any staged changes\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "test_diff = \"\"\"\n",
    "    diff --git a/script.sh b/script.sh\n",
    "    index 1234567..89abcde 100644\n",
    "    --- a/script.sh\n",
    "    +++ b/script.sh\n",
    "    @@ -1,3 +1,7 @@\n",
    "    +fi\n",
    "    +\n",
    "    +# Check if there are any staged changes\n",
    "    +diff=$(git diff --cached | cat)\n",
    "    +if [ -z \"$diff\" ]; then\n",
    "    +  echo \"No staged changes to commit.\"\n",
    "    +  exit 1\n",
    "    \"\"\"\n",
    "    \n",
    "analyze_git_change(test_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knoten definieren\n",
    "from langgraph.prebuilt import ToolNode\n",
    "import json\n",
    "from langchain_core.messages import ToolMessage, SystemMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "tools = [parse_git_diff, GitFileChange]\n",
    "agent_llm = agent_llm.bind_tools(tools)\n",
    "\n",
    "def call_model(\n",
    "    state: AgentState,\n",
    "    config: RunnableConfig,\n",
    "):\n",
    "    # this is similar to customizing the create_react_agent with state_modifier, but is a lot more flexible\n",
    "    system_prompt = SystemMessage(\n",
    "        \"You are a helpful AI assistant, please respond to the users query to the best of your ability!\"\n",
    "    )\n",
    "    response = agent_llm.invoke([system_prompt] + state[\"messages\"], config)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", ToolNode(tools))\n",
    "workflow.add_node(\"respond\", respond)\n",
    "\n",
    "# Entrypoint setzen\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# Bedingte Kanten hinzufügen\n",
    "def should_continue(state: AgentState):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if not last_message.tool_calls:\n",
    "        return \"respond\"\n",
    "    return \"continue\"\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"tools\",\n",
    "        \"respond\": \"respond\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Normale Kanten\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "workflow.add_edge(\"respond\", END)\n",
    "\n",
    "# Graph kompilieren\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human: Parse the following git-diff: \n",
      "\n",
      "    diff --git a/old-name.ts b/new-name.ts\n",
      "    similarity index 100%\n",
      "    rename from old-name.ts\n",
      "    rename to new-name.ts\n",
      "\n",
      "human: Parse the following git-diff: \n",
      "\n",
      "    diff --git a/old-name.ts b/new-name.ts\n",
      "    similarity index 100%\n",
      "    rename from old-name.ts\n",
      "    rename to new-name.ts\n",
      "\n",
      "ai: Based on the provided Git-Diff, here is the parsed information:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"change_type\": \"rename\",\n",
      "  \"purpose\": \"The file was renamed from 'old-name.ts' to 'new-name.ts'\",\n",
      "  \"hunks\": [],\n",
      "  \"added_lines\": 0,\n",
      "  \"removed_lines\": 0,\n",
      "  \"path\": \"new-name.ts\"\n",
      "}\n",
      "```\n",
      "Finale strukturierte Antwort:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Helper function für die Ausgabe\n",
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        if \"final_response\" in s:\n",
    "            print(\"Finale strukturierte Antwort:\")\n",
    "            print(s[\"final_response\"])\n",
    "        elif \"messages\" in s:\n",
    "            for msg in s[\"messages\"]:\n",
    "                if hasattr(msg, \"content\"):\n",
    "                    print(f\"{msg.type}: {msg.content}\")\n",
    "\n",
    "# Test-Diff\n",
    "diff = \"\"\"Parse the following git-diff: \\n\n",
    "    diff --git a/old-name.ts b/new-name.ts\n",
    "    similarity index 100%\n",
    "    rename from old-name.ts\n",
    "    rename to new-name.ts\n",
    "\"\"\"\n",
    "\n",
    "# Eingabe vorbereiten\n",
    "inputs = {\n",
    "    \"messages\": [HumanMessage(content=diff)]\n",
    "}\n",
    "\n",
    "# Graph ausführen und Ergebnisse ausgeben\n",
    "print_stream(graph.stream(inputs, stream_mode=\"values\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\\n\\n\n",
    "    diff --git a/git-ai-commit.sh b/git-ai-commit.sh\n",
    "new file mode 100755\n",
    "index 0000000000..d7cf9c8873\n",
    "--- /dev/null\n",
    "+++ b/git-ai-commit.sh\n",
    "@@ -0,0 +1,57 @@\n",
    "+#!/bin/bash\n",
    "+\n",
    "+# Check if files are passed as arguments or if the user wants to add all changes\n",
    "+if [ \"$#\" -eq 0 ]; then\n",
    "+  echo \"No files specified. Staging all changes...\"\n",
    "+  git add .\n",
    "+else\n",
    "+  echo \"Staging specified files...\"\n",
    "+  git add \"$@\"\n",
    "+fi\n",
    "+\n",
    "+# Check if there are any staged changes\n",
    "+diff=$(git diff --cached | cat)\n",
    "+if [ -z \"$diff\" ]; then\n",
    "+  echo \"No staged changes to commit.\"\n",
    "+  exit 1\n",
    "+fi\n",
    "+\n",
    "+# Escape the diff for JSON compatibility\n",
    "+escaped_diff=$(echo \"$diff\" | jq -Rsa .)\n",
    "+\n",
    "+# Prepare the payload for Ollama\n",
    "+data=$(jq -n --arg diff \"$escaped_diff\" '{\n",
    "+  \"model\": \"llama3.2\",\n",
    "+  \"stream\": false,\n",
    "+  \"prompt\": (\"\" + $diff)\n",
    "+}')\n",
    "+\n",
    "+# Call the Ollama API to generate the commit message\n",
    "+response=$(curl -s -X POST http://localhost:11434/api/generate -d \"$data\" -H \"Content-Type: application/json\")\n",
    "+\n",
    "+# Extract the commit message from the API response\n",
    "+commit_message=$(echo \"$response\" | jq -r '.response')\n",
    "+\n",
    "+# Check if a commit message was generated\n",
    "+if [ -z \"$commit_message\" ]; then\n",
    "+  echo \"Error: Failed to generate a commit message.\"\n",
    "+  exit 1\n",
    "+fi\n",
    "+\n",
    "+# Display the generated commit message in the console\n",
    "+echo \"AI-Generated Commit Message:\"\n",
    "+echo \"--------------------------------------\"\n",
    "+echo \"$commit_message\"\n",
    "+echo \"--------------------------------------\"\n",
    "+\n",
    "+# Confirm with the user before committing\n",
    "+read -p \"Do you want to use this commit message? (y/n): \" confirm\n",
    "+if [[ \"$confirm\" != \"y\" ]]; then\n",
    "+  echo \"Commit aborted.\"\n",
    "+  exit 1\n",
    "+fi\n",
    "+\n",
    "+# Use the generated commit message directly in the commit\n",
    "+git commit -m \"$commit_message\"\n",
    "+\n",
    "+echo \"Commit created successfully with AI-generated message!\"\n",
    "\\ No newline at end of file\n",
    "diff --git a/packages/react/docs/ai-optimization.md b/packages/react/docs/ai-optimization.md\n",
    "new file mode 100644\n",
    "index 0000000000..fc725e8385\n",
    "--- /dev/null\n",
    "+++ b/packages/react/docs/ai-optimization.md\n",
    "@@ -0,0 +1,16 @@\n",
    "+\n",
    "+# AI-Powered Code Optimization\n",
    "+\n",
    "+This module provides real-time code analysis and optimization suggestions using AI.\n",
    "+\n",
    "+## Features\n",
    "+- Real-time code analysis\n",
    "+- Performance metrics collection\n",
    "+- AI-powered suggestions\n",
    "+- Pattern detection\n",
    "+\n",
    "+## Architecture\n",
    "+- AICodeOptimizer: Core orchestration\n",
    "+- CodeAnalyzer: Static analysis\n",
    "+- MetricsCollector: Runtime metrics\n",
    "+\n",
    "diff --git a/packages/react/src/ai/optimizer.ts b/packages/react/src/ai/optimizer.ts\n",
    "new file mode 100644\n",
    "index 0000000000..0e1fcd4606\n",
    "--- /dev/null\n",
    "+++ b/packages/react/src/ai/optimizer.ts\n",
    "@@ -0,0 +1,18 @@\n",
    "+\n",
    "+import { OpenAI } from \"./ai/openai\";\n",
    "+import { CodeAnalyzer } from \"./analysis/code\";\n",
    "+import { MetricsCollector } from \"./metrics/collector\";\n",
    "+\n",
    "+export class AICodeOptimizer {\n",
    "+  constructor() {\n",
    "+    this.ai = new OpenAI();\n",
    "+    this.analyzer = new CodeAnalyzer();\n",
    "+    this.metrics = new MetricsCollector();\n",
    "+  }\n",
    "+\n",
    "+  async analyze(code: string) {\n",
    "+    const metrics = await this.metrics.collect(code);\n",
    "+    const analysis = await this.analyzer.analyze(code);\n",
    "+    return this.ai.suggest(metrics, analysis);\n",
    "+  }\n",
    "+}\n",
    "diff --git a/packages/react/src/analysis/code.ts b/packages/react/src/analysis/code.ts\n",
    "new file mode 100644\n",
    "index 0000000000..66ae5494fd\n",
    "--- /dev/null\n",
    "+++ b/packages/react/src/analysis/code.ts\n",
    "@@ -0,0 +1,10 @@\n",
    "+\n",
    "+export class CodeAnalyzer {\n",
    "+  analyze(code: string) {\n",
    "+    return {\n",
    "+      complexity: this.calculateComplexity(code),\n",
    "+      patterns: this.detectPatterns(code),\n",
    "+      issues: this.findIssues(code)\n",
    "+    };\n",
    "+  }\n",
    "+}\n",
    "diff --git a/packages/react/src/components/CodeOptimizationPanel.tsx b/packages/react/src/components/CodeOptimizationPanel.tsx\n",
    "new file mode 100644\n",
    "index 0000000000..cacb561952\n",
    "--- /dev/null\n",
    "+++ b/packages/react/src/components/CodeOptimizationPanel.tsx\n",
    "@@ -0,0 +1,22 @@\n",
    "+\n",
    "+import { AICodeOptimizer } from \"../ai/optimizer\";\n",
    "+import { useEffect, useState } from \"react\";\n",
    "+\n",
    "+export const CodeOptimizationPanel = () => {\n",
    "+  const [optimizer] = useState(() => new AICodeOptimizer());\n",
    "+  const [suggestions, setSuggestions] = useState([]);\n",
    "+\n",
    "+  useEffect(() => {\n",
    "+    optimizer.analyze(currentCode)\n",
    "+      .then(setSuggestions);\n",
    "+  }, [currentCode]);\n",
    "+\n",
    "+  return (\n",
    "+    <div className=\"optimization-panel\">\n",
    "+      <h2>AI Suggestions</h2>\n",
    "+      {suggestions.map(suggestion => (\n",
    "+        <SuggestionCard key={suggestion.id} {...suggestion} />\n",
    "+      ))}\n",
    "+    </div>\n",
    "+  );\n",
    "+}\n",
    "diff --git a/packages/react/src/config/ai.ts b/packages/react/src/config/ai.ts\n",
    "new file mode 100644\n",
    "index 0000000000..d0cc0c275c\n",
    "--- /dev/null\n",
    "+++ b/packages/react/src/config/ai.ts\n",
    "@@ -0,0 +1,14 @@\n",
    "+\n",
    "+export const config = {\n",
    "+  ai: {\n",
    "+    model: \"gpt-4\",\n",
    "+    temperature: 0.2,\n",
    "+    maxTokens: 1000\n",
    "+  },\n",
    "+  analysis: {\n",
    "+    thresholds: {\n",
    "+      complexity: 20,\n",
    "+      issues: 5\n",
    "+    }\n",
    "+  }\n",
    "+}\n",
    "diff --git a/packages/react/src/metrics/collector.ts b/packages/react/src/metrics/collector.ts\n",
    "new file mode 100644\n",
    "index 0000000000..1f544f7352\n",
    "--- /dev/null\n",
    "+++ b/packages/react/src/metrics/collector.ts\n",
    "@@ -0,0 +1,10 @@\n",
    "+\n",
    "+export class MetricsCollector {\n",
    "+  collect(code: string) {\n",
    "+    return {\n",
    "+      performance: this.measurePerformance(code),\n",
    "+      memory: this.analyzeMemory(code),\n",
    "+      dependencies: this.checkDependencies(code)\n",
    "+    };\n",
    "+  }\n",
    "+}\n",
    "diff --git a/packages/react/src/types/analysis.ts b/packages/react/src/types/analysis.ts\n",
    "new file mode 100644\n",
    "index 0000000000..c52d0a4f85\n",
    "--- /dev/null\n",
    "+++ b/packages/react/src/types/analysis.ts\n",
    "@@ -0,0 +1,15 @@\n",
    "+\n",
    "+export interface CodeAnalysis {\n",
    "+  complexity: {\n",
    "+    cognitive: number;\n",
    "+    cyclomatic: number;\n",
    "+  };\n",
    "+  patterns: {\n",
    "+    antiPatterns: string[];\n",
    "+    improvements: string[];\n",
    "+  };\n",
    "+  issues: {\n",
    "+    performance: string[];\n",
    "+    security: string[];\n",
    "+  };\n",
    "+}\n",
    "   \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "withray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
